{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input/Output\n",
    "\n",
    "> This module manages where downloaded data is stored via a config\n",
    "file. It also provides a PathManager class to retrieve the paths to files in\n",
    "the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import toml\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configfile\n",
    "\n",
    "The config file for now just contains one path to the folder where all data for `pyciss` will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Config:\n",
    "    \"\"\"Manage config stuff.\n",
    "\n",
    "    Attributes\n",
    "    -------\n",
    "    path: pathlib.Path\n",
    "    \n",
    "    The key, value pairs found in the config file become attributes of the\n",
    "    class instance after initialization.\n",
    "    At minimum, there should be the `archive_path` attribute for storing data\n",
    "    for this package.\n",
    "    \"\"\"\n",
    "    # This enables a config path location override using env PYCISS_CONFIG\n",
    "    path = Path(os.getenv(\"PYCISS_CONFIG\", Path.home() / '.pyciss.toml'))\n",
    "\n",
    "    def __init__(self, other_config=None):\n",
    "        \"Switch to other config file location with `other_config`.\"\n",
    "        if other_config is not None:\n",
    "            self.path = Path(other_config)\n",
    "        self.get_config()\n",
    "\n",
    "    def get_config(self):\n",
    "        \"Read the configfile and store config dict.\"\n",
    "        p = self.path\n",
    "        if not p.exists():\n",
    "            self.not_found()\n",
    "        else:\n",
    "            with open(p) as f:\n",
    "                self.d = toml.load(f)\n",
    "                if not self.d:\n",
    "                    self.not_found()\n",
    "                # all found key.value pairs become attributes\n",
    "                for k, v in self.d.items():\n",
    "                    setattr(self, k, v)\n",
    "\n",
    "    def not_found(self):\n",
    "        \"\"\"Use input to ask user for the archive_path. \n",
    "        \n",
    "        The path will be stored in the config file `Class.path` (either default or as given\n",
    "        during init.)\n",
    "        \"\"\"\n",
    "        path = input(\"Provide path where all package data will be stored:\")\n",
    "        d = {}\n",
    "        d[\"archive_path\"] = path\n",
    "        self.archive_path = path\n",
    "        with self.path.open(\"w\") as f:\n",
    "            toml.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/maye/big_drive/planetary_data/pyciss'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.archive_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Config` object init will ask for an input path if the config file is not found or empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Config.not_found\" class=\"doc_header\"><code>Config.not_found</code><a href=\"__main__.py#L37\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Config.not_found</code>()\n",
       "\n",
       "```\n",
       "Use input to ask user for the archive_path. \n",
       "\n",
       "The path will be stored in the config file `Class.path` (either default or as given\n",
       "during init.)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Config.not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this, we need to catch the UI `input()` call and provide a default output that would be entered as the `archive_path` into the `Config` object.\n",
    "\n",
    "First, we create a random temporary file for a new config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmp349bqoil'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tempfile for testing\n",
    "import tempfile\n",
    "f = tempfile.NamedTemporaryFile()\n",
    "f.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we store the pointer to the `input` function as a backup, and patch the `input` function to return a test archive_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store pointer of input function\n",
    "old_input = input\n",
    "# patch input function for testing\n",
    "input = lambda x: \"/some/path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new Config object. As it has no archive path in it, the patched `input` call of `Class.not_found` will return the above test path.\n",
    "In reality, the user will provide the path to the `input` prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new Config object with temporayr\n",
    "c = Config(f.name)\n",
    "\n",
    "assert toml.load(f.name)['archive_path'] == \"/some/path\"\n",
    "\n",
    "#return stored pointer to the input function:\n",
    "input = old_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_db_root():\n",
    "    dbroot = Path(config.archive_path)\n",
    "    dbroot.mkdir(exist_ok=True)\n",
    "    return dbroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/maye/big_drive/planetary_data/pyciss')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_db_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PathManager\n",
    "\n",
    "> The `PathManager` provides access to the paths in the archive, based on class attributes that reflect the processing level of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "\n",
    "class PathManager:\n",
    "\n",
    "    \"\"\"Manage paths to data in database.\n",
    "\n",
    "    The `.pyciss.toml` config file determines the path to the database for ISS images.\n",
    "    With this class you can access the different kind of files conveniently.\n",
    "\n",
    "    Using the stored extensions dictionary, the attributes of the object listed here are created\n",
    "    dynamically at object initialization and when the image_id is being set.\n",
    "\n",
    "    NOTE\n",
    "    ----\n",
    "    This class will read the .pyciss.toml to define the dbroot path, but\n",
    "    one can also call it with the savedir argument to override that.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_id : str or pathlib.Path\n",
    "        The N... or W... image identifier string of CISS images or the absolute\n",
    "        path to an existing image\n",
    "    savedir : str or pathlib.Path\n",
    "        Path to the pyciss image database. By default defined by what's found in\n",
    "        the .pyciss.yaml config, but can be overridden using this parameter.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    basepath\n",
    "    img_id\n",
    "    calib_img\n",
    "    calib_label\n",
    "    raw_image\n",
    "    raw_cub\n",
    "    raw_label\n",
    "    cubepath\n",
    "    tif\n",
    "    undestriped\n",
    "    \"\"\"\n",
    "\n",
    "    d = {\n",
    "        'cubepath': '.cal.dst.map.cub',\n",
    "        'cal_cub': '.cal.cub',\n",
    "        'dst_cub': '.cal.dst.cub',\n",
    "        'raw_cub': '.cub',\n",
    "        'raw_label': '.LBL',\n",
    "        'raw_image': '.IMG',\n",
    "        'calib_img': '_CALIB.IMG',\n",
    "        'calib_label': '_CALIB.LBL',\n",
    "        'tif': '.cal.dst.map.tif',\n",
    "        'undestriped': '.cal.map.cub'\n",
    "    }\n",
    "    # ordered, sorted by key:\n",
    "    extensions = OrderedDict(sorted(d.items(), key=lambda t: t[0]))\n",
    "\n",
    "    def __init__(self, img_id, savedir=None):\n",
    "        img_id = img_id.upper()\n",
    "        self.input_img_id = img_id\n",
    "        if Path(img_id).is_absolute():\n",
    "            # the split is to remove the _1.IMG or _2.IMG from the path\n",
    "            # for the image id.\n",
    "            self._id = Path(img_id).name.split('_')[0]\n",
    "        else:\n",
    "            # I'm using only filename until _ for storage\n",
    "            # TODO: Could this create a problem?\n",
    "            self._id = img_id[:11]\n",
    "        if savedir is None:\n",
    "            self.dbroot = get_db_root()\n",
    "        else:\n",
    "            self.dbroot = Path(savedir)\n",
    "\n",
    "        self.set_version()\n",
    "        self.set_attributes()\n",
    "\n",
    "    def set_version(self):\n",
    "        id_ = Path(self.input_img_id).name\n",
    "        if len(id_) > 11:\n",
    "            self.version = id_.split('_')[1].split('.')[0]\n",
    "        else:\n",
    "            # if the given id was without version, check if a raw file is in database:\n",
    "            try:\n",
    "                rawpath = next(self.basepath.glob(self.img_id + \"_?.IMG\")).name\n",
    "            except StopIteration:\n",
    "                self.version = '0'\n",
    "            else:\n",
    "                self.version = rawpath[12]\n",
    "\n",
    "    @property\n",
    "    def basepath(self):\n",
    "        return self.dbroot / self._id\n",
    "\n",
    "    @property\n",
    "    def img_id(self):\n",
    "        return self._id\n",
    "\n",
    "    @img_id.setter\n",
    "    def img_id(self, value):\n",
    "        self._id = value\n",
    "        self.set_attributes()\n",
    "\n",
    "    def set_attributes(self):\n",
    "        for k, v in self.extensions.items():\n",
    "            path = self.basepath / f\"{self.img_id}_{self.version}{v}\"\n",
    "            setattr(self, k, path)\n",
    "\n",
    "    def __str__(self):\n",
    "        self.set_version()\n",
    "        self.set_attributes()  # in case there were changes\n",
    "        s = ''\n",
    "        for k, v in self.extensions.items():\n",
    "            s += \"{}: \".format(k)\n",
    "            path = getattr(self, k)\n",
    "            if path.exists():\n",
    "                s += \"{}\\n\".format(path)\n",
    "            else:\n",
    "                s += \"not found.\\n\"\n",
    "        return s\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def db_mapped_cubes():\n",
    "    return get_db_root().glob(\"**/*cal.dst.map.cub\")\n",
    "\n",
    "\n",
    "def db_label_paths():\n",
    "    return get_db_root().glob(\"*.LBL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.cal.dst.map.cub')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db_mapped_cubes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PathManager('N1875229393')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cal_cub: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.cal.cub\n",
       "calib_img: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1_CALIB.IMG\n",
       "calib_label: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1_CALIB.LBL\n",
       "cubepath: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.cal.dst.map.cub\n",
       "dst_cub: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.cal.dst.cub\n",
       "raw_cub: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.cub\n",
       "raw_image: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.IMG\n",
       "raw_label: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.LBL\n",
       "tif: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.cal.dst.map.tif\n",
       "undestriped: /home/maye/big_drive/planetary_data/pyciss/N1875229393/N1875229393_1.cal.map.cub"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cal_cub', '.cal.cub'),\n",
       "             ('calib_img', '_CALIB.IMG'),\n",
       "             ('calib_label', '_CALIB.LBL'),\n",
       "             ('cubepath', '.cal.dst.map.cub'),\n",
       "             ('dst_cub', '.cal.dst.cub'),\n",
       "             ('raw_cub', '.cub'),\n",
       "             ('raw_image', '.IMG'),\n",
       "             ('raw_label', '.LBL'),\n",
       "             ('tif', '.cal.dst.map.tif'),\n",
       "             ('undestriped', '.cal.map.cub')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_db_stats():\n",
    "    \"\"\"Print database stats.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Table with the found data items per type.\n",
    "    \"\"\"\n",
    "    dbroot = get_db_root()\n",
    "    print(f\"Database location: {dbroot}\")\n",
    "    n_ids = len(list(dbroot.glob(\"[N,W]*\")))\n",
    "    print(\"Number of WACs and NACs in database: {}\".format(n_ids))\n",
    "    print(\"These kind of data are in the database: (returning pd.DataFrame)\")\n",
    "    d = {}\n",
    "    for key, val in PathManager.extensions.items():\n",
    "        d[key] = [len(list(dbroot.glob(\"**/*_?\" + val)))]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database location: /home/maye/big_drive/planetary_data/pyciss\n",
      "Number of WACs and NACs in database: 1\n",
      "These kind of data are in the database: (returning pd.DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cal_cub</th>\n",
       "      <th>calib_img</th>\n",
       "      <th>calib_label</th>\n",
       "      <th>cubepath</th>\n",
       "      <th>dst_cub</th>\n",
       "      <th>raw_cub</th>\n",
       "      <th>raw_image</th>\n",
       "      <th>raw_label</th>\n",
       "      <th>tif</th>\n",
       "      <th>undestriped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cal_cub  calib_img  calib_label  cubepath  dst_cub  raw_cub  raw_image  \\\n",
       "0        1          1            1         1        1        1          1   \n",
       "\n",
       "   raw_label  tif  undestriped  \n",
       "0          1    1            1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_db_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DBManager():\n",
    "    \"\"\"Helper class for the whole archive.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.dbroot = get_db_root()\n",
    "\n",
    "    def print_stats(self):\n",
    "        print_db_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def filename_from_obsid(obsid):\n",
    "    tokens = obsid.split('_')\n",
    "    return f\"{tokens[-1]}{tokens[-2]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_io.ipynb.\n",
      "Converted 01_opusapi.ipynb.\n",
      "Converted 02_pipeline.ipynb.\n",
      "Converted 03_ringutils.ipynb.\n",
      "Converted 04_plotting.ipynb.\n",
      "Converted 05_index.ipynb.\n",
      "Converted 06_ringcube.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted to_be_implemented.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
